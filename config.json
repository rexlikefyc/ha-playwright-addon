# å°å…¥å¿…è¦çš„å‡½å¼åº«
# Import necessary libraries
import requests
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import re
import calendar
import numpy as np
from bs4 import BeautifulSoup
import logging
import time
import subprocess
import sys

# ç¢ºä¿ xlsxwriter å‡½å¼åº«å·²å®‰è£
# Ensure the xlsxwriter library is installed
try:
    import xlsxwriter
except ImportError:
    print("âŒ åµæ¸¬åˆ° xlsxwriter å‡½å¼åº«æœªå®‰è£ï¼Œæ­£åœ¨ç‚ºæ‚¨å®‰è£...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "xlsxwriter"])
    print("âœ… xlsxwriter å‡½å¼åº«å®‰è£æˆåŠŸï¼")

# è¨­å®šæ—¥èªŒ
# Set up logging to a file.
logging.basicConfig(filename="/config/scrape_log_twse.txt", level=logging.INFO, encoding="utf-8", format="%(asctime)s - %(levelname)s - %(message)s")

def roc_to_ad(roc_date_str):
    """
    å°‡æ°‘åœ‹æ—¥æœŸå­—ä¸²è½‰æ›ç‚ºè¥¿å…ƒæ—¥æœŸç‰©ä»¶ã€‚
    Converts a Republic of China (ROC) date string to a datetime object.
    """
    try:
        y, m, d = map(int, roc_date_str.strip().split("/"))
        return datetime(y + 1911, m, d)
    except:
        return None

def get_latest_trade_date(year, month):
    """
    ç²å–æŒ‡å®šå¹´æœˆçš„æœ€å¾Œäº¤æ˜“æ—¥ã€‚
    Gets the last trading day of the specified year and month.
    """
    _, last_day = calendar.monthrange(year, month)
    end_date = datetime(year, month, last_day)
    while end_date.weekday() >= 5: # 5=é€±å…­, 6=é€±æ—¥
        end_date -= timedelta(days=1)
    return end_date

def get_twse_stock_list():
    """
    å–å¾—ä¸Šå¸‚è‚¡ç¥¨æ¸…å–®ã€‚
    Gets the list of TWSE listed stocks.
    """
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers)
        r.raise_for_status()
        dfs = pd.read_html(r.text)
        df = dfs[0]
        df.columns = df.iloc[0]
        df = df[1:]
        df = df[df["æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±"].apply(lambda x: bool(re.match(r"^\d{4}", str(x))))]
        df["stock_id"] = df["æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±"].str.extract(r"^(\d{4})")
        df["name"] = df["æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±"].str.extract(r"^\d{4}\s+(.+)")
        df = df[["stock_id", "name"]].dropna()
        logging.info(f"ğŸ” æŠ“å–åˆ° {len(df)} æª”ä¸Šå¸‚è‚¡ç¥¨")
        return df
    except Exception as e:
        logging.error(f"âŒ è‚¡ç¥¨æ¸…å–®æŠ“å–å¤±æ•—: {e}")
        return None

def fetch_twse_history(stock_id, year, month):
    """
    æŠ“å–æŒ‡å®šå¹´æœˆçš„æ•´æœˆæ­·å²è³‡æ–™ã€‚
    Fetches a full month's historical data for a specific stock.
    """
    date_str = f"{year}{month:02d}01"
    url = f"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date={date_str}&stockNo={stock_id}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=5)
        r.raise_for_status()
        data = r.json()
        if data.get("stat") != "OK":
            return None, f"API å›å‚³å¤±æ•—: {data.get('stat')} ({year}/{month:02d})"
        df = pd.DataFrame(data["data"], columns=data["fields"])
        if df.empty:
            return None, f"è³‡æ–™ç‚ºç©º ({year}/{month:02d})"
        if "æ—¥æœŸ" not in df.columns or "æ”¶ç›¤åƒ¹" not in df.columns or "æˆäº¤è‚¡æ•¸" not in df.columns or "é–‹ç›¤åƒ¹" not in df.columns:
            return None, f"ç¼ºå°‘å¿…è¦æ¬„ä½: {df.columns} ({year}/{month:02d})"
        df["æ—¥æœŸ"] = df["æ—¥æœŸ"].apply(roc_to_ad)
        df["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df["æ”¶ç›¤åƒ¹"].str.replace(",", ""), errors="coerce")
        df["é–‹ç›¤åƒ¹"] = pd.to_numeric(df["é–‹ç›¤åƒ¹"].str.replace(",", ""), errors="coerce")
        df["æˆäº¤å¼µæ•¸"] = pd.to_numeric(df["æˆäº¤è‚¡æ•¸"].str.replace(",", ""), errors="coerce") / 1000
        df = df[["æ—¥æœŸ", "æ”¶ç›¤åƒ¹", "é–‹ç›¤åƒ¹", "æˆäº¤å¼µæ•¸"]].dropna().sort_values("æ—¥æœŸ")
        if df.empty:
            return None, f"è³‡æ–™è™•ç†å¾Œç‚ºç©º ({year}/{month:02d})"
        return df, None
    except requests.exceptions.RequestException as e:
        return None, f"è«‹æ±‚å¤±æ•—: {e} ({year}/{month:02d})"

def calculate_rsi(df, period=14):
    """
    ä½¿ç”¨ Wilder's æ–¹æ³•è¨ˆç®— RSIã€‚
    Calculates the Relative Srength Index (RSI) using Wilder's method.
    """
    delta = df["æ”¶ç›¤åƒ¹"].diff()
    gain = delta.where(delta > 0, 0.0)
    loss = -delta.where(delta < 0, 0.0)
    
    # ä½¿ç”¨æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š (EMA)
    # Use Exponential Moving Average (EMA)
    avg_gain = gain.ewm(com=period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=period - 1, adjust=False).mean()
    
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    
    # è™•ç†åˆ†æ¯ç‚º 0 çš„æƒ…æ³
    # Handle the case where the denominator is 0
    rsi = rsi.fillna(100)
    
    return rsi.round(2)

def fetch_industry_chain_info(stock_code):
    """
    å¾ç”¢æ¥­åƒ¹å€¼éˆå¹³å°ç¶²é æŠ“å–å…¬å¸æ‰€å±¬ç”¢æ¥­èˆ‡ç”¢æ¥­éˆè³‡è¨Šã€‚
    Fetches the company's industry and industry chain information from the
    Industry Value Chain Platform website, handling encoding issues.
    """
    url = f"https://ic.tpex.org.tw/company_chain.php?stk_code={stock_code}"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    industry_info = {
        "industry": "N/A",
        "industry_chain": "N/A"
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        # å˜—è©¦ç”¨ UTF-8 è§£ç¢¼ï¼Œå¦‚æœå¤±æ•—å‰‡æ”¹ç”¨ cp950 (Big5 çš„ Windows æ“´å……)
        # Try to decode with UTF-8, if it fails, switch to cp950 (Windows extension of Big5)
        try:
            response.encoding = 'utf-8'
            response_text = response.text
        except UnicodeDecodeError:
            response.encoding = 'cp950'
            response_text = response.text
            
        soup = BeautifulSoup(response_text, 'html.parser')

        # å°‹æ‰¾æ‰€æœ‰åŒ…å«ç”¢æ¥­éˆè³‡è¨Šçš„ <h4> æ¨™ç±¤
        # Find all <h4> tags that contain the industry chain information
        industry_elements = soup.select('div.content h4 a')

        if industry_elements:
            industries = []
            industry_chains = []
            for element in industry_elements:
                # æ“·å–æ‰€å±¬ç”¢æ¥­
                # Extract the industry
                industries.append(element.text.strip())
                
                # æ“·å–ç”¢æ¥­éˆï¼Œå®ƒä½æ–¼ <a> æ¨™ç±¤çš„ä¸‹ä¸€å€‹å…„å¼Ÿç¯€é»
                # Extract the industry chain, which is the next sibling of the <a> tag
                industry_chain_text = element.next_sibling
                if industry_chain_text:
                    # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—å…ƒå’Œ ">" ç¬¦è™Ÿ
                    # Remove all whitespace and ">" symbols
                    cleaned_text = industry_chain_text.strip().replace('>', '').replace('&gt;', '').strip()
                    industry_chains.append(cleaned_text)
            
            industry_info["industry"] = ", ".join(industries)
            industry_info["industry_chain"] = ", ".join(industry_chains)
        
        return industry_info

    except requests.exceptions.RequestException as e:
        logging.error(f"è‚¡ç¥¨ {stock_code} ç”¢æ¥­éˆç¶²é æŠ“å–å¤±æ•—: {e}")
        return industry_info
    except Exception as e:
        logging.error(f"è‚¡ç¥¨ {stock_code} ç”¢æ¥­éˆè³‡æ–™è§£æå¤±æ•—: {e}")
        return industry_info

def analyze_twse_stocks(year_month=None):
    """
    åˆ†æä¸Šå¸‚è‚¡ç¥¨ä¸¦ç¯©é¸ç¬¦åˆç‰¹å®šæ¢ä»¶çš„è‚¡ç¥¨ã€‚
    Analyzes listed stocks and filters them based on multiple criteria.
    """
    if year_month is None:
        year_month = datetime.today().strftime("%Y/%m")
    try:
        year, month = map(int, year_month.split("/"))
    except:
        logging.error("âŒ å¹´æœˆæ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º YYYY/MM")
        print("âŒ å¹´æœˆæ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º YYYY/MM")
        return

    stock_df = get_twse_stock_list()
    if stock_df is None or stock_df.empty:
        logging.error("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹å¼çµ‚æ­¢")
        print("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹å¼çµ‚æ­¢")
        return

    target_date = get_latest_trade_date(year, month)
    
    results_conditions_1_4 = []
    results_condition_5 = []
    
    total = len(stock_df)
    logging.info(f"ğŸ” å…±éœ€åˆ†æ {total} æª”è‚¡ç¥¨")
    print(f"ğŸ” å…±éœ€åˆ†æ {total} æª”è‚¡ç¥¨")

    def process_stock(stock_info):
        stock_id, stock_name = stock_info
        
        df_all = []
        for m in range(2):
            target_year = year
            target_month = month - m
            if target_month <= 0:
                target_year -= 1
                target_month += 12
            df, reason = fetch_twse_history(stock_id, target_year, target_month)
            if df is not None and not df.empty:
                df_all.append(df)
        
        df_all = [df for df in df_all if not df.empty]
        if not df_all:
            logging.warning(f"è‚¡ç¥¨ {stock_id} ç„¡æœ‰æ•ˆæ­·å²è³‡æ–™")
            return None
            
        df = pd.concat(df_all, ignore_index=True).drop_duplicates(subset=["æ—¥æœŸ"]).sort_values("æ—¥æœŸ")
        
        if len(df) < 20:
            logging.warning(f"è‚¡ç¥¨ {stock_id} è³‡æ–™ä¸è¶³20å¤©: {len(df)}")
            return None

        df = df[df["æ—¥æœŸ"] <= target_date].reset_index(drop=True)
        
        if len(df) < 20:
            logging.warning(f"è‚¡ç¥¨ {stock_id} ç¯©é¸å¾Œè³‡æ–™ä¸è¶³20å¤©: {len(df)}")
            return None

        df["MA5"] = df["æ”¶ç›¤åƒ¹"].rolling(window=5).mean().round(2)
        df["MA10"] = df["æ”¶ç›¤åƒ¹"].rolling(window=10).mean().round(2)
        df["MA20"] = df["æ”¶ç›¤åƒ¹"].rolling(window=20).mean().round(2)
        df["Volume_MA5"] = df["æˆäº¤å¼µæ•¸"].rolling(window=5).mean().round(0)
        df["Volume_MA10"] = df["æˆäº¤å¼µæ•¸"].rolling(window=10).mean().round(0)
        df["RSI"] = calculate_rsi(df, period=14)

        if len(df) < 3:
            logging.warning(f"è‚¡ç¥¨ {stock_id} æ•¸æ“šä¸è¶³ä»¥é€²è¡Œåˆ†æï¼Œè‡³å°‘éœ€è¦3å¤©")
            return None

        latest = df.iloc[-1]
        one_day_ago = df.iloc[-2]
        two_days_ago = df.iloc[-3]

        if pd.isna(latest["æˆäº¤å¼µæ•¸"]) or latest["æˆäº¤å¼µæ•¸"] < 200:
            logging.warning(f"è‚¡ç¥¨ {stock_id} æˆäº¤é‡ä¸è¶³200å¼µæˆ–ç„¡æ•ˆ: {latest['æˆäº¤å¼µæ•¸']}")
            return None

        ma10_minus_ma5_pct = ((latest["MA10"] - latest["MA5"]) / latest["MA5"] * 100) if not pd.isna(latest["MA5"]) and latest["MA5"] != 0 else float("inf")

        # --- æ¢å¾©äº¤æ˜“é‡é‚è¼¯ (æ¢ä»¶1-4) ---
        # --- Restored volume logic (for conditions 1-4) ---
        volume_condition_1_4_met = False
        volume_multiplier_1_4_output = 0.0
        for i in range(3):
            day_df = df.iloc[-1-i]
            if pd.isna(day_df["æˆäº¤å¼µæ•¸"]) or pd.isna(day_df["Volume_MA5"]) or pd.isna(day_df["Volume_MA10"]) or pd.isna(day_df["æ”¶ç›¤åƒ¹"]) or pd.isna(day_df["é–‹ç›¤åƒ¹"]):
                continue
            
            # æª¢æŸ¥ç´…Kç·šèˆ‡æˆäº¤é‡çˆ†ç™¼æ¢ä»¶
            # Check for red candle and volume breakout condition
            if (day_df["æ”¶ç›¤åƒ¹"] > day_df["é–‹ç›¤åƒ¹"] and 
                day_df["æˆäº¤å¼µæ•¸"] >= day_df["Volume_MA5"] * 1.5 and 
                day_df["æˆäº¤å¼µæ•¸"] >= day_df["Volume_MA10"] * 1.5):
                
                # è¨ˆç®—å€æ•¸ (æˆäº¤é‡ / max(5æ—¥å‡é‡, 10æ—¥å‡é‡))
                # Calculate multiplier (volume / max(5-day MA, 10-day MA))
                volume_multiplier_1_4_output = day_df["æˆäº¤å¼µæ•¸"] / max(day_df["Volume_MA5"], day_df["Volume_MA10"])
                volume_condition_1_4_met = True
                break # æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„ç´…Kï¼Œè·³å‡ºè¿´åœˆ

        # --- äº¤æ˜“é‡é‚è¼¯ (æ¢ä»¶5) ---
        # --- Volume logic (for condition 5) ---
        volume_condition_5_met = False
        volume_multiplier_5_output = 0.0
        if not pd.isna(latest["æˆäº¤å¼µæ•¸"]) and not pd.isna(latest["Volume_MA5"]) and not pd.isna(latest["Volume_MA10"]):
            if (latest["æˆäº¤å¼µæ•¸"] >= latest["Volume_MA5"] * 2 and
                latest["æˆäº¤å¼µæ•¸"] >= latest["Volume_MA10"] * 2):
                volume_condition_5_met = True
                volume_multiplier_5_output = latest["æˆäº¤å¼µæ•¸"] / max(latest["Volume_MA5"], latest["Volume_MA10"])

        conditions_met = []
        
        # Condition 1: 5-day MA crosses above 10-day and 20-day MAs, and RSI >= 49
        if (volume_condition_1_4_met and
            0 <= ma10_minus_ma5_pct < 1 and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] < latest["MA10"] and latest["MA10"] < latest["MA20"] and
            not pd.isna(one_day_ago["MA5"]) and
            latest["MA5"] > one_day_ago["MA5"] and
            not pd.isna(latest["RSI"]) and latest["RSI"] >= 49):
            conditions_met.append("æ¢ä»¶1")

        # Condition 2: 5-day MA crosses above 10-day and 20-day MAs, and RSI rises from low
        if (volume_condition_1_4_met and
            0 <= ma10_minus_ma5_pct < 1 and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] < latest["MA10"] and latest["MA10"] < latest["MA20"] and
            not pd.isna(one_day_ago["MA5"]) and
            latest["MA5"] > one_day_ago["MA5"] and
            not pd.isna(latest["RSI"]) and not pd.isna(one_day_ago["RSI"]) and
            latest["RSI"] < 49 and latest["RSI"] > one_day_ago["RSI"]):
            conditions_met.append("æ¢ä»¶2")

        # Condition 3: 5-day MA crosses above 10-day MA, and RSI >= 50
        if (volume_condition_1_4_met and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] > latest["MA10"] and
            latest["MA10"] < latest["MA5"] and latest["MA5"] < latest["MA20"] and
            not pd.isna(one_day_ago["MA5"]) and not pd.isna(one_day_ago["MA10"]) and
            one_day_ago["MA5"] <= one_day_ago["MA10"] and
            not pd.isna(latest["RSI"]) and latest["RSI"] >= 50):
            conditions_met.append("æ¢ä»¶3")

        # Condition 4: 5-day, 10-day, and 20-day MAs are in a bullish trend, and RSI >= 50
        if (volume_condition_1_4_met and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA10"] < latest["MA5"] and latest["MA5"] < latest["MA20"] and
            not pd.isna(latest["RSI"]) and latest["RSI"] >= 50):
            conditions_met.append("æ¢ä»¶4")

        # Condition 5: Current closing price is above the 20-day MA, and current day's volume > 2x of both 5-day and 10-day MAs
        if (volume_condition_5_met and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] > latest["MA20"]):
            conditions_met.append("æ¢ä»¶5")

        if not conditions_met:
            return None
            
        industry_info = fetch_industry_chain_info(stock_id)

        output_data = {
            "stock_id": stock_id,
            "stock_name": stock_name,
            "close_price": f"{latest['æ”¶ç›¤åƒ¹']:.2f}",
            "conditions_met": ", ".join(conditions_met),
            "industry": industry_info["industry"],
            "industry_chain": industry_info["industry_chain"],
            "ma10_minus_ma5": ((latest['MA10'] - latest['MA5']) / latest['MA5'] * 100) if not pd.isna(latest["MA5"]) and latest["MA5"] != 0 else float("inf")
        }

        if "æ¢ä»¶5" in conditions_met:
            output_data["volume_multiplier"] = f"{volume_multiplier_5_output:.2f}"
        else:
            output_data["volume_multiplier"] = f"{volume_multiplier_1_4_output:.2f}"
        
        logging.info(f"è‚¡ç¥¨ {stock_id} ç¬¦åˆæ¢ä»¶: {output_data['conditions_met']}")
        return output_data

    stock_list = list(stock_df[["stock_id", "name"]].itertuples(index=False, name=None))
    
    with ThreadPoolExecutor(max_workers=20) as executor:
        pre_filtered_results = list(executor.map(process_stock, stock_list))

    condition5_stocks = []
    other_stocks = []

    for r in pre_filtered_results:
        if r is not None:
            if "æ¢ä»¶5" in r.get("conditions_met", ""):
                condition5_stocks.append(r)
            else:
                other_stocks.append(r)

    final_columns = [
        "è‚¡ç¥¨ä»£è™Ÿ",
        "è‚¡ç¥¨åç¨±",
        "ç•¶æ—¥æ”¶ç›¤åƒ¹",
        "äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡çš„å€æ•¸",
        "ç¬¦åˆæ¢ä»¶",
        "æ‰€å±¬ç”¢æ¥­",
        "ç”¢æ¥­éˆ"
    ]
    
    # ç”¢å‡ºã€Œå…¶ä»–ã€ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æª”æ¡ˆ
    if other_stocks:
        other_df = pd.DataFrame(other_stocks)
        other_df = other_df.sort_values(by=["ma10_minus_ma5", "volume_multiplier"], ascending=[True, False])
        other_df = other_df[[
            "stock_id", "stock_name", "close_price", "volume_multiplier", "conditions_met",
            "industry", "industry_chain"
        ]]
        other_df.columns = final_columns
        output_file_other = f"/config/filtered_twse_stocks_others_{year}_{month:02d}.csv"
        other_df.to_csv(output_file_other, index=False, encoding="utf-8-sig")
        logging.info(f"å…¶ä»–ç¬¦åˆæ¢ä»¶è‚¡ç¥¨å·²è¼¸å‡ºè‡³ {output_file_other}ï¼Œå…± {len(other_stocks)} æª”")
        print(f"âœ… å…¶ä»–ç¬¦åˆæ¢ä»¶è‚¡ç¥¨å…± {len(other_stocks)} æª”")
    else:
        output_file_other = f"/config/filtered_twse_stocks_others_{year}_{month:02d}.csv"
        with open(output_file_other, "w", encoding="utf-8-sig") as f:
            f.write("è‚¡ç¥¨ä»£è™Ÿ,è‚¡ç¥¨åç¨±,ç•¶æ—¥æ”¶ç›¤åƒ¹,äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡çš„å€æ•¸,ç¬¦åˆæ¢ä»¶,æ‰€å±¬ç”¢æ¥­,ç”¢æ¥­éˆ\n")
            f.write("ç„¡å…¶ä»–ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
        logging.info("ç„¡å…¶ä»–ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
        print("âœ… ç„¡å…¶ä»–ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")

    # ç”¢å‡ºã€Œæ¢ä»¶äº”ã€ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æª”æ¡ˆ
    if condition5_stocks:
        condition5_df = pd.DataFrame(condition5_stocks)
        condition5_df = condition5_df.sort_values(by="volume_multiplier", ascending=False)
        condition5_df = condition5_df[[
            "stock_id", "stock_name", "close_price", "volume_multiplier", "conditions_met",
            "industry", "industry_chain"
        ]]
        condition5_df.columns = final_columns
        output_file_condition5 = f"/config/filtered_twse_stocks_condition5_{year}_{month:02d}.csv"
        condition5_df.to_csv(output_file_condition5, index=False, encoding="utf-8-sig")
        logging.info(f"ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨å·²è¼¸å‡ºè‡³ {output_file_condition5}ï¼Œå…± {len(condition5_stocks)} æª”")
        print(f"âœ… ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨å…± {len(condition5_stocks)} æª”")
    else:
        output_file_condition5 = f"/config/filtered_twse_stocks_condition5_{year}_{month:02d}.csv"
        with open(output_file_condition5, "w", encoding="utf-8-sig") as f:
            f.write("è‚¡ç¥¨ä»£è™Ÿ,è‚¡ç¥¨åç¨±,ç•¶æ—¥æ”¶ç›¤åƒ¹,äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡çš„å€æ•¸,ç¬¦åˆæ¢ä»¶,æ‰€å±¬ç”¢æ¥­,ç”¢æ¥­éˆ\n")
            f.write("ç„¡ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨")
        logging.info("ç„¡ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨")
        print("âœ… ç„¡ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨")

    logging.info(f"åˆ†æå®Œæˆï¼Œçµæœè¼¸å‡ºè‡³ {output_file_other} èˆ‡ {output_file_condition5}")
    print(f"âœ… åˆ†æå®Œæˆï¼Œçµæœè¼¸å‡ºè‡³ {output_file_other} èˆ‡ {output_file_condition5}")
    

if __name__ == "__main__":
    start_time = time.time()
    analyze_twse_stocks()
    end_time = time.time()
    logging.info(f"Total execution time: {end_time - start_time:.2f} seconds")

