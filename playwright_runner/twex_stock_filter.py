# å°å…¥å¿…è¦çš„å‡½å¼åº«
# Import necessary libraries
import requests
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import calendar
import numpy as np
import time
import logging
import random
import json
import io
from bs4 import BeautifulSoup
import subprocess
import sys
import os # æ–°å¢ os å‡½å¼åº«

# ç¢ºä¿ xlsxwriter å‡½å¼åº«å·²å®‰è£
# Ensure the xlsxwriter library is installed
try:
    import xlsxwriter
except ImportError:
    print("âŒ åµæ¸¬åˆ° xlsxwriter å‡½å¼åº«æœªå®‰è£ï¼Œæ­£åœ¨ç‚ºæ‚¨å®‰è£...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "xlsxwriter"])
    print("âœ… xlsxwriter å‡½å¼åº«å®‰è£æˆåŠŸï¼")

# æª¢æŸ¥ä¸¦å»ºç«‹ç›®éŒ„
# Check and create the directory
log_dir = "/config"
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# è¨­å®šæ—¥èªŒ
# Set up logging to a file.
logging.basicConfig(filename="/config/scrape_log.txt", level=logging.INFO, encoding="utf-8", format="%(asctime)s - %(levelname)s - %(message)s")

def roc_to_ad(roc_date_str):
    """
    å°‡æ°‘åœ‹æ—¥æœŸå­—ä¸²è½‰æ›ç‚ºè¥¿å…ƒæ—¥æœŸç‰©ä»¶ã€‚
    Converts a Republic of China (ROC) date string to a datetime object.
    Example: '113/05/20' -> 2024-05-20 00:00:00
    """
    try:
        y, m, d = map(int, roc_date_str.strip().split("/"))
        return datetime(y + 1911, m, d)
    except:
        return None

def get_latest_trade_date(year, month):
    """
    ç²å–æŒ‡å®šå¹´æœˆçš„æœ€å¾Œäº¤æ˜“æ—¥ã€‚
    Gets the last trading day of a given year and month.
    """
    _, last_day = calendar.monthrange(year, month)
    end_date = datetime(year, month, last_day)
    while end_date.weekday() >= 5: # 5=é€±å…­, 6=é€±æ—¥
        end_date -= timedelta(days=1)
    return end_date

def fetch_tpex_stock_list():
    """
    å–å¾—ä¸Šæ«ƒè‚¡ç¥¨æ¸…å–®ã€‚
    Fetches the list of TWEX (Taipei Exchange) listed stocks.
    """
    url = "https://www.tpex.org.tw/www/zh-tw/afterTrading/dailyMarktVal"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()
        data = r.json()
        logging.info(f"å¸‚å€¼æ’è¡Œ API å›æ‡‰: {data.get('date', 'ç„¡æ—¥æœŸ')}ï¼Œç¸½è‚¡ç¥¨æ•¸: {data.get('totalCount', 'æœªçŸ¥')}")
        if not data.get("tables"):
            logging.error("æ²’æœ‰æ‰¾åˆ°è¡¨æ ¼æ•¸æ“š")
            return None
        table = data["tables"][0]
        df = pd.DataFrame(table["data"], columns=table["fields"])
        df = df[df["è‚¡ç¥¨ä»£è™Ÿ"].notnull() & (df["è‚¡ç¥¨ä»£è™Ÿ"].astype(str).str.len() > 0)]
        df = df[["è‚¡ç¥¨ä»£è™Ÿ", "è‚¡ç¥¨åç¨±"]].rename(columns={"è‚¡ç¥¨ä»£è™Ÿ": "stock_id", "è‚¡ç¥¨åç¨±": "name"})
        logging.info(f"æŠ“å–åˆ° {len(df)} æª”ä¸Šæ«ƒè‚¡ç¥¨")
        return df
    except Exception as e:
        logging.error(f"è‚¡ç¥¨æ¸…å–®æŠ“å–å¤±æ•—: {e}")
        return None

def fetch_tpex_history(stock_id, year, month):
    """
    æŠ“å–æŒ‡å®šå¹´æœˆçš„æ•´æœˆæ­·å²è³‡æ–™ã€‚
    Fetches a full month's historical data for a specific stock.
    """
    date_str = f"{year}/{month:02d}/01"
    url = f"https://www.tpex.org.tw/www/zh-tw/afterTrading/tradingStock?response=&date={date_str}&code={stock_id}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()
        data = r.json()
        if data.get("stat") != "ok":
            return None, f"API å›å‚³å¤±æ•—: {data.get('stat')} ({year}/{month:02d})"
        table = data["tables"][0]
        df = pd.DataFrame(table["data"], columns=table["fields"])
        if df.empty:
            return None, f"è³‡æ–™ç‚ºç©º ({year}/{month:02d})"
        if "æ—¥ æœŸ" not in df.columns or "æ”¶ç›¤" not in df.columns or "æˆäº¤å¼µæ•¸" not in df.columns or "é–‹ç›¤" not in df.columns:
            return None, f"ç¼ºå°‘å¿…è¦æ¬„ä½: {df.columns} ({year}/{month:02d})"
        df["æ—¥æœŸ"] = df["æ—¥ æœŸ"].apply(roc_to_ad)
        df["æ”¶ç›¤åƒ¹"] = pd.to_numeric(df["æ”¶ç›¤"].str.replace(",", ""), errors="coerce")
        df["é–‹ç›¤åƒ¹"] = pd.to_numeric(df["é–‹ç›¤"].str.replace(",", ""), errors="coerce")
        df["æˆäº¤å¼µæ•¸"] = pd.to_numeric(df["æˆäº¤å¼µæ•¸"].str.replace(",", ""), errors="coerce")
        df = df[["æ—¥æœŸ", "æ”¶ç›¤åƒ¹", "é–‹ç›¤åƒ¹", "æˆäº¤å¼µæ•¸"]].dropna().sort_values("æ—¥æœŸ")
        if df.empty:
            return None, f"è³‡æ–™è™•ç†å¾Œç‚ºç©º ({year}/{month:02d})"
        return df, None
    except requests.exceptions.RequestException as e:
        return None, f"è«‹æ±‚å¤±æ•—: {e} ({year}/{month:02d})"

def fetch_industry_chain_info(stock_code):
    """
    å¾ç”¢æ¥­åƒ¹å€¼éˆå¹³å°ç¶²é æŠ“å–å…¬å¸æ‰€å±¬ç”¢æ¥­èˆ‡ç”¢æ¥­éˆè³‡è¨Šï¼Œä¸¦è™•ç†ç·¨ç¢¼å•é¡Œã€‚
    Fetches the company's industry and industry chain information from the
    Industry Value Chain Platform website, handling encoding issues.
    """
    url = f"https://ic.tpex.org.tw/company_chain.php?stk_code={stock_code}"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    industry_info = {
        "industry": "N/A",
        "industry_chain": "N/A"
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        # å˜—è©¦ç”¨ UTF-8 è§£ç¢¼ï¼Œå¦‚æœå¤±æ•—å‰‡æ”¹ç”¨ cp950 (Big5 çš„ Windows æ“´å……)
        # Try to decode with UTF-8, if it fails, switch to cp950 (Windows extension of Big5)
        try:
            response.encoding = 'utf-8'
            response_text = response.text
        except UnicodeDecodeError:
            response.encoding = 'cp950'
            response_text = response.text
            
        soup = BeautifulSoup(response_text, 'html.parser')

        # å°‹æ‰¾æ‰€æœ‰åŒ…å«ç”¢æ¥­éˆè³‡è¨Šçš„ <h4> æ¨™ç±¤
        # Find all <h4> tags that contain the industry chain information
        industry_elements = soup.select('div.content h4 a')

        if industry_elements:
            industries = []
            industry_chains = []
            for element in industry_elements:
                # æ“·å–æ‰€å±¬ç”¢æ¥­
                # Extract the industry
                industries.append(element.text.strip())
                
                # æ“·å–ç”¢æ¥­éˆï¼Œå®ƒä½æ–¼ <a> æ¨™ç±¤çš„ä¸‹ä¸€å€‹å…„å¼Ÿç¯€é»
                # Extract the industry chain, which is the next sibling of the <a> tag
                industry_chain_text = element.next_sibling
                if industry_chain_text:
                    # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—å…ƒå’Œ ">" ç¬¦è™Ÿ
                    # Remove all whitespace and ">" symbols
                    cleaned_text = industry_chain_text.strip().replace('>', '').replace('&gt;', '').strip()
                    industry_chains.append(cleaned_text)
            
            industry_info["industry"] = ", ".join(industries)
            industry_info["industry_chain"] = ", ".join(industry_chains)
        
        return industry_info

    except requests.exceptions.RequestException as e:
        logging.error(f"è‚¡ç¥¨ {stock_code} ç”¢æ¥­éˆç¶²é æŠ“å–å¤±æ•—: {e}")
        return industry_info
    except Exception as e:
        logging.error(f"è‚¡ç¥¨ {stock_code} ç”¢æ¥­éˆè³‡æ–™è§£æå¤±æ•—: {e}")
        return industry_info

def calculate_rsi(df, period=14):
    """
    ä½¿ç”¨ Wilder's æ–¹æ³•è¨ˆç®— RSIã€‚
    Calculates the Relative Srength Index (RSI) using Wilder's method.
    """
    delta = df["æ”¶ç›¤åƒ¹"].diff()
    gain = delta.where(delta > 0, 0.0)
    loss = -delta.where(delta < 0, 0.0)
    
    # ä½¿ç”¨æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š (EMA)
    # Use Exponential Moving Average (EMA)
    avg_gain = gain.ewm(com=period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=period - 1, adjust=False).mean()
    
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    
    # è™•ç†åˆ†æ¯ç‚º 0 çš„æƒ…æ³
    # Handle the case where the denominator is 0
    rsi = rsi.fillna(100)
    
    return rsi.round(2)

def analyze_tpex_stocks(year_month=None):
    """
    åˆ†æä¸Šæ«ƒè‚¡ç¥¨ä¸¦ç¯©é¸ç¬¦åˆç‰¹å®šæ¢ä»¶çš„è‚¡ç¥¨ã€‚
    Analyzes TWEX stocks and filters them based on specific conditions.
    """
    if year_month is None:
        year_month = datetime.today().strftime("%Y/%m")
    try:
        year, month = map(int, year_month.split("/"))
    except:
        logging.error("å¹´æœˆæ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º YYYY/MM")
        print("âŒ å¹´æœˆæ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º YYYY/MM")
        return

    stock_df = fetch_tpex_stock_list()
    if stock_df is None or stock_df.empty:
        logging.error("ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹å¼çµ‚æ­¢")
        print("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹å¼çµ‚æ­¢")
        return

    target_date = get_latest_trade_date(year, month)
    pre_filtered_results = []
    total = len(stock_df)
    logging.info(f"å…±éœ€åˆ†æ {total} æª”è‚¡ç¥¨")
    print(f"ğŸ” å…±éœ€åˆ†æ {total} æª”è‚¡ç¥¨")

    def process_stock(stock_info):
        stock_id, stock_name = stock_info
        df_all = []
        for m in range(2):
            target_year = year
            target_month = month - m
            if target_month <= 0:
                target_year -= 1
                target_month += 12
            df, reason = fetch_tpex_history(stock_id, target_year, target_month)
            if df is not None and not df.empty:
                df_all.append(df)
            else:
                logging.warning(f"è‚¡ç¥¨ {stock_id} æ­·å²è³‡æ–™æŠ“å–å¤±æ•—: {reason}")
        
        df_all = [df for df in df_all if not df.empty]
        if not df_all:
            logging.warning(f"è‚¡ç¥¨ {stock_id} ç„¡æœ‰æ•ˆæ­·å²è³‡æ–™")
            return None
        
        df = pd.concat(df_all, ignore_index=True).drop_duplicates(subset=["æ—¥æœŸ"]).sort_values("æ—¥æœŸ")
        
        if len(df) < 20:
            logging.warning(f"è‚¡ç¥¨ {stock_id} è³‡æ–™ä¸è¶³20å¤©: {len(df)}")
            return None

        df = df[df["æ—¥æœŸ"] <= target_date].reset_index(drop=True)
        
        if len(df) < 20:
            logging.warning(f"è‚¡ç¥¨ {stock_id} ç¯©é¸å¾Œè³‡æ–™ä¸è¶³20å¤©: {len(df)}")
            return None

        df["MA5"] = df["æ”¶ç›¤åƒ¹"].rolling(window=5).mean().round(2)
        df["MA10"] = df["æ”¶ç›¤åƒ¹"].rolling(window=10).mean().round(2)
        df["MA20"] = df["æ”¶ç›¤åƒ¹"].rolling(window=20).mean().round(2)
        df["Volume_MA5"] = df["æˆäº¤å¼µæ•¸"].rolling(window=5).mean().round(0)
        df["Volume_MA10"] = df["æˆäº¤å¼µæ•¸"].rolling(window=10).mean().round(0)
        df["RSI"] = calculate_rsi(df, period=14)

        if len(df) < 3:
            logging.warning(f"è‚¡ç¥¨ {stock_id} æ•¸æ“šä¸è¶³ä»¥é€²è¡Œåˆ†æï¼Œè‡³å°‘éœ€è¦3å¤©")
            return None

        latest = df.iloc[-1]
        one_day_ago = df.iloc[-2]
        two_days_ago = df.iloc[-3]

        if pd.isna(latest["æˆäº¤å¼µæ•¸"]) or latest["æˆäº¤å¼µæ•¸"] < 200:
            logging.warning(f"è‚¡ç¥¨ {stock_id} æˆäº¤é‡ä¸è¶³200å¼µæˆ–ç„¡æ•ˆ: {latest['æˆäº¤å¼µæ•¸']}")
            return None

        ma10_minus_ma5_pct = ((latest["MA10"] - latest["MA5"]) / latest["MA5"] * 100) if not pd.isna(latest["MA5"]) and latest["MA5"] != 0 else float("inf")

        # --- æ¢å¾©äº¤æ˜“é‡é‚è¼¯ (æ¢ä»¶1-4) ---
        # --- Restored volume logic (for conditions 1-4) ---
        volume_condition_1_4_met = False
        volume_multiplier_1_4_output = 0.0
        for i in range(3):
            day_df = df.iloc[-1-i]
            if pd.isna(day_df["æˆäº¤å¼µæ•¸"]) or pd.isna(day_df["Volume_MA5"]) or pd.isna(day_df["Volume_MA10"]) or pd.isna(day_df["æ”¶ç›¤åƒ¹"]) or pd.isna(day_df["é–‹ç›¤åƒ¹"]):
                continue
            
            # æª¢æŸ¥ç´…Kç·šèˆ‡æˆäº¤é‡çˆ†ç™¼æ¢ä»¶
            # Check for red candle and volume breakout condition
            if (day_df["æ”¶ç›¤åƒ¹"] > day_df["é–‹ç›¤åƒ¹"] and 
                day_df["æˆäº¤å¼µæ•¸"] >= day_df["Volume_MA5"] * 1.5 and 
                day_df["æˆäº¤å¼µæ•¸"] >= day_df["Volume_MA10"] * 1.5):
                
                # è¨ˆç®—å€æ•¸ (æˆäº¤é‡ / max(5æ—¥å‡é‡, 10æ—¥å‡é‡))
                # Calculate multiplier (volume / max(5-day MA, 10-day MA))
                volume_multiplier_1_4_output = day_df["æˆäº¤å¼µæ•¸"] / max(day_df["Volume_MA5"], day_df["Volume_MA10"])
                volume_condition_1_4_met = True
                break # æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„ç´…Kï¼Œè·³å‡ºè¿´åœˆ

        # --- äº¤æ˜“é‡é‚è¼¯ (æ¢ä»¶5) ---
        # --- Volume logic (for condition 5) ---
        volume_condition_5_met = False
        volume_multiplier_5_output = 0.0
        if not pd.isna(latest["æˆäº¤å¼µæ•¸"]) and not pd.isna(latest["Volume_MA5"]) and not pd.isna(latest["Volume_MA10"]):
            if (latest["æˆäº¤å¼µæ•¸"] >= latest["Volume_MA5"] * 2 and
                latest["æˆäº¤å¼µæ•¸"] >= latest["Volume_MA10"] * 2):
                volume_condition_5_met = True
                volume_multiplier_5_output = latest["æˆäº¤å¼µæ•¸"] / max(latest["Volume_MA5"], latest["Volume_MA10"])

        conditions_met = []
        
        # æ¢ä»¶1: MA10-MA5 å·®è· 0-1%ï¼Œä¸” MA5 < MA10 < MA20ï¼Œä¸” MA5 ä¸Šå‡ï¼Œä¸” RSI >= 49
        if (volume_condition_1_4_met and
            0 <= ma10_minus_ma5_pct < 1 and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] < latest["MA10"] and latest["MA10"] < latest["MA20"] and
            not pd.isna(one_day_ago["MA5"]) and
            latest["MA5"] > one_day_ago["MA5"] and
            not pd.isna(latest["RSI"]) and latest["RSI"] >= 49):
            conditions_met.append("æ¢ä»¶1")

        # æ¢ä»¶2: MA10-MA5 å·®è· 0-1%ï¼Œä¸” MA5 < MA10 < MA20ï¼Œä¸” MA5 ä¸Šå‡ï¼Œä¸” RSI < 49 ä½†ä¸Šå‡
        if (volume_condition_1_4_met and
            0 <= ma10_minus_ma5_pct < 1 and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] < latest["MA10"] and latest["MA10"] < latest["MA20"] and
            not pd.isna(one_day_ago["MA5"]) and
            latest["MA5"] > one_day_ago["MA5"] and
            not pd.isna(latest["RSI"]) and not pd.isna(one_day_ago["RSI"]) and
            latest["RSI"] < 49 and latest["RSI"] > one_day_ago["RSI"]):
            conditions_met.append("æ¢ä»¶2")

        # æ¢ä»¶3: MA5 > MA10ï¼Œä¸” MA10 < MA5 < MA20ï¼Œä¸”å‰ä¸€æ—¥ MA5 <= MA10ï¼Œä¸” RSI >= 50
        if (volume_condition_1_4_met and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] > latest["MA10"] and
            latest["MA10"] < latest["MA5"] and latest["MA5"] < latest["MA20"] and
            not pd.isna(one_day_ago["MA5"]) and not pd.isna(one_day_ago["MA10"]) and
            one_day_ago["MA5"] <= one_day_ago["MA10"] and
            not pd.isna(latest["RSI"]) and latest["RSI"] >= 50):
            conditions_met.append("æ¢ä»¶3")

        # æ¢ä»¶4: MA10 < MA5 < MA20ï¼Œä¸” RSI >= 50
        if (volume_condition_1_4_met and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA10"]) and not pd.isna(latest["MA20"]) and
            latest["MA10"] < latest["MA5"] and latest["MA5"] < latest["MA20"] and
            not pd.isna(latest["RSI"]) and latest["RSI"] >= 50):
            conditions_met.append("æ¢ä»¶4")

        # æ¢ä»¶5: ç•¶æ—¥ MA5 > MA20ï¼Œä¸”ç•¶æ—¥äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡å€æ•¸ >= 2
        if (volume_condition_5_met and
            not pd.isna(latest["MA5"]) and not pd.isna(latest["MA20"]) and
            latest["MA5"] > latest["MA20"]):
            conditions_met.append("æ¢ä»¶5")

        if not conditions_met:
            return None
            
        industry_info = fetch_industry_chain_info(stock_id)

        output_data = {
            "stock_id": stock_id,
            "stock_name": stock_name,
            "close_price": f"{latest['æ”¶ç›¤åƒ¹']:.2f}",
            "conditions_met": ", ".join(conditions_met),
            "industry": industry_info["industry"],
            "industry_chain": industry_info["industry_chain"],
            "ma10_minus_ma5": ((latest['MA10'] - latest['MA5']) / latest['MA5'] * 100) if not pd.isna(latest["MA5"]) and latest["MA5"] != 0 else float("inf")
        }

        if "æ¢ä»¶5" in conditions_met:
            output_data["volume_multiplier"] = f"{volume_multiplier_5_output:.2f}"
        else:
            output_data["volume_multiplier"] = f"{volume_multiplier_1_4_output:.2f}"
            
        logging.info(f"è‚¡ç¥¨ {stock_id} ç¬¦åˆæ¢ä»¶: {output_data['conditions_met']}")
        return output_data

    stock_list = list(stock_df[["stock_id", "name"]].itertuples(index=False, name=None))
    
    with ThreadPoolExecutor(max_workers=20) as executor:
        pre_filtered_results = list(executor.map(process_stock, stock_list))

    condition5_stocks = []
    other_stocks = []

    for r in pre_filtered_results:
        if r is not None:
            if "æ¢ä»¶5" in r.get("conditions_met", ""):
                condition5_stocks.append(r)
            else:
                other_stocks.append(r)

    final_columns = [
        "è‚¡ç¥¨ä»£è™Ÿ",
        "è‚¡ç¥¨åç¨±",
        "ç•¶æ—¥æ”¶ç›¤åƒ¹",
        "äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡çš„å€æ•¸",
        "ç¬¦åˆæ¢ä»¶",
        "æ‰€å±¬ç”¢æ¥­",
        "ç”¢æ¥­éˆ"
    ]
    
    # ç”¢å‡ºã€Œå…¶ä»–ã€ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æª”æ¡ˆ
    if other_stocks:
        other_df = pd.DataFrame(other_stocks)
        other_df = other_df.sort_values(by=["ma10_minus_ma5", "volume_multiplier"], ascending=[True, False])
        other_df = other_df[[
            "stock_id", "stock_name", "close_price", "volume_multiplier", "conditions_met",
            "industry", "industry_chain"
        ]]
        other_df.columns = final_columns
        output_file_other = f"/config/filtered_tpex_stocks_others_{year}_{month:02d}.csv"
        other_df.to_csv(output_file_other, index=False, encoding="utf-8-sig")
        logging.info(f"å…¶ä»–ç¬¦åˆæ¢ä»¶è‚¡ç¥¨å·²è¼¸å‡ºè‡³ {output_file_other}ï¼Œå…± {len(other_stocks)} æª”")
        print(f"âœ… å…¶ä»–ç¬¦åˆæ¢ä»¶è‚¡ç¥¨å…± {len(other_stocks)} æª”")
    else:
        output_file_other = f"/config/filtered_tpex_stocks_others_{year}_{month:02d}.csv"
        with open(output_file_other, "w", encoding="utf-8-sig") as f:
            f.write("è‚¡ç¥¨ä»£è™Ÿ,è‚¡ç¥¨åç¨±,ç•¶æ—¥æ”¶ç›¤åƒ¹,äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡çš„å€æ•¸,ç¬¦åˆæ¢ä»¶,æ‰€å±¬ç”¢æ¥­,ç”¢æ¥­éˆ\n")
            f.write("ç„¡å…¶ä»–ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
        logging.info("ç„¡å…¶ä»–ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
        print("âœ… ç„¡å…¶ä»–ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")

    # ç”¢å‡ºã€Œæ¢ä»¶äº”ã€ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æª”æ¡ˆ
    if condition5_stocks:
        condition5_df = pd.DataFrame(condition5_stocks)
        condition5_df = condition5_df.sort_values(by="volume_multiplier", ascending=False)
        condition5_df = condition5_df[[
            "stock_id", "stock_name", "close_price", "volume_multiplier", "conditions_met",
            "industry", "industry_chain"
        ]]
        condition5_df.columns = final_columns
        output_file_condition5 = f"/config/filtered_tpex_stocks_condition5_{year}_{month:02d}.csv"
        condition5_df.to_csv(output_file_condition5, index=False, encoding="utf-8-sig")
        logging.info(f"ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨å·²è¼¸å‡ºè‡³ {output_file_condition5}ï¼Œå…± {len(condition5_stocks)} æª”")
        print(f"âœ… ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨å…± {len(condition5_stocks)} æª”")
    else:
        output_file_condition5 = f"/config/filtered_tpex_stocks_condition5_{year}_{month:02d}.csv"
        with open(output_file_condition5, "w", encoding="utf-8-sig") as f:
            f.write("è‚¡ç¥¨ä»£è™Ÿ,è‚¡ç¥¨åç¨±,ç•¶æ—¥æ”¶ç›¤åƒ¹,äº¤æ˜“é‡è¶…é5æˆ–10æœ€å¤šå‡é‡çš„å€æ•¸,ç¬¦åˆæ¢ä»¶,æ‰€å±¬ç”¢æ¥­,ç”¢æ¥­éˆ\n")
            f.write("ç„¡ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨")
        logging.info("ç„¡ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨")
        print("âœ… ç„¡ç¬¦åˆæ¢ä»¶äº”çš„è‚¡ç¥¨")

    logging.info(f"åˆ†æå®Œæˆï¼Œçµæœè¼¸å‡ºè‡³ {output_file_other} èˆ‡ {output_file_condition5}")
    print(f"âœ… åˆ†æå®Œæˆï¼Œçµæœè¼¸å‡ºè‡³ {output_file_other} èˆ‡ {output_file_condition5}")
    

if __name__ == "__main__":
    start_time = time.time()
    analyze_tpex_stocks()
    end_time = time.time()
    logging.info(f"Total execution time: {end_time - start_time:.2f} seconds")
